{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "name": "open-source-ai-models",
  "version": "1.0.0",
  "description": "Safe, auditable open-source AI model configurations. All models are forkable and inspectable.",

  "principles": {
    "transparency": "All models must have open weights and be fully inspectable",
    "auditability": "Model training data and methodology must be documented",
    "safety": "Models are evaluated for harmful outputs before integration",
    "forkability": "All models can be forked, fine-tuned, and self-hosted"
  },

  "providers": {
    "ollama": {
      "description": "Run open-source LLMs locally",
      "endpoint": "http://localhost:11434",
      "docs": "https://ollama.ai",
      "selfHosted": true,
      "openSource": true
    },
    "huggingface": {
      "description": "Hugging Face Inference API and Hub",
      "endpoint": "https://api-inference.huggingface.co",
      "docs": "https://huggingface.co/docs",
      "selfHosted": true,
      "openSource": true
    },
    "vllm": {
      "description": "High-throughput LLM serving",
      "endpoint": "http://localhost:8000",
      "docs": "https://docs.vllm.ai",
      "selfHosted": true,
      "openSource": true
    },
    "llamacpp": {
      "description": "C++ inference for GGUF models",
      "endpoint": "http://localhost:8080",
      "docs": "https://github.com/ggerganov/llama.cpp",
      "selfHosted": true,
      "openSource": true
    }
  },

  "models": {
    "large_language_models": {
      "llama3": {
        "name": "Meta Llama 3",
        "sizes": ["8B", "70B"],
        "license": "Llama 3 Community License",
        "huggingface": "meta-llama/Meta-Llama-3-8B-Instruct",
        "ollama": "llama3",
        "capabilities": ["text-generation", "chat", "reasoning"],
        "safetyReview": "passed",
        "forkable": true
      },
      "llama3.1": {
        "name": "Meta Llama 3.1",
        "sizes": ["8B", "70B", "405B"],
        "license": "Llama 3.1 Community License",
        "huggingface": "meta-llama/Llama-3.1-8B-Instruct",
        "ollama": "llama3.1",
        "capabilities": ["text-generation", "chat", "reasoning", "tool-use"],
        "safetyReview": "passed",
        "forkable": true
      },
      "mistral": {
        "name": "Mistral AI",
        "sizes": ["7B"],
        "license": "Apache 2.0",
        "huggingface": "mistralai/Mistral-7B-Instruct-v0.3",
        "ollama": "mistral",
        "capabilities": ["text-generation", "chat"],
        "safetyReview": "passed",
        "forkable": true
      },
      "mixtral": {
        "name": "Mixtral MoE",
        "sizes": ["8x7B", "8x22B"],
        "license": "Apache 2.0",
        "huggingface": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "ollama": "mixtral",
        "capabilities": ["text-generation", "chat", "multilingual"],
        "safetyReview": "passed",
        "forkable": true
      },
      "qwen2": {
        "name": "Qwen 2",
        "sizes": ["0.5B", "1.5B", "7B", "72B"],
        "license": "Apache 2.0",
        "huggingface": "Qwen/Qwen2-7B-Instruct",
        "ollama": "qwen2",
        "capabilities": ["text-generation", "chat", "code", "multilingual"],
        "safetyReview": "passed",
        "forkable": true
      },
      "phi3": {
        "name": "Microsoft Phi-3",
        "sizes": ["mini-4k", "mini-128k", "small", "medium"],
        "license": "MIT",
        "huggingface": "microsoft/Phi-3-mini-4k-instruct",
        "ollama": "phi3",
        "capabilities": ["text-generation", "chat", "reasoning"],
        "safetyReview": "passed",
        "forkable": true
      },
      "gemma2": {
        "name": "Google Gemma 2",
        "sizes": ["2B", "9B", "27B"],
        "license": "Gemma License",
        "huggingface": "google/gemma-2-9b-it",
        "ollama": "gemma2",
        "capabilities": ["text-generation", "chat"],
        "safetyReview": "passed",
        "forkable": true
      },
      "deepseek_coder": {
        "name": "DeepSeek Coder",
        "sizes": ["1.3B", "6.7B", "33B"],
        "license": "DeepSeek License",
        "huggingface": "deepseek-ai/deepseek-coder-6.7b-instruct",
        "ollama": "deepseek-coder",
        "capabilities": ["code-generation", "code-completion", "chat"],
        "safetyReview": "passed",
        "forkable": true
      },
      "codellama": {
        "name": "Code Llama",
        "sizes": ["7B", "13B", "34B", "70B"],
        "license": "Llama 2 Community License",
        "huggingface": "codellama/CodeLlama-7b-Instruct-hf",
        "ollama": "codellama",
        "capabilities": ["code-generation", "code-completion", "infilling"],
        "safetyReview": "passed",
        "forkable": true
      },
      "starcoder2": {
        "name": "StarCoder2",
        "sizes": ["3B", "7B", "15B"],
        "license": "BigCode OpenRAIL-M",
        "huggingface": "bigcode/starcoder2-15b",
        "ollama": "starcoder2",
        "capabilities": ["code-generation", "code-completion"],
        "safetyReview": "passed",
        "forkable": true
      }
    },

    "embedding_models": {
      "nomic_embed": {
        "name": "Nomic Embed",
        "dimensions": 768,
        "license": "Apache 2.0",
        "huggingface": "nomic-ai/nomic-embed-text-v1.5",
        "ollama": "nomic-embed-text",
        "capabilities": ["text-embedding", "semantic-search"],
        "safetyReview": "passed",
        "forkable": true
      },
      "mxbai_embed": {
        "name": "MixedBread Embed",
        "dimensions": 1024,
        "license": "Apache 2.0",
        "huggingface": "mixedbread-ai/mxbai-embed-large-v1",
        "ollama": "mxbai-embed-large",
        "capabilities": ["text-embedding", "semantic-search"],
        "safetyReview": "passed",
        "forkable": true
      },
      "bge": {
        "name": "BGE Embeddings",
        "dimensions": 1024,
        "license": "MIT",
        "huggingface": "BAAI/bge-large-en-v1.5",
        "capabilities": ["text-embedding", "semantic-search"],
        "safetyReview": "passed",
        "forkable": true
      }
    },

    "vision_models": {
      "llava": {
        "name": "LLaVA",
        "sizes": ["7B", "13B", "34B"],
        "license": "Apache 2.0",
        "huggingface": "llava-hf/llava-v1.6-mistral-7b-hf",
        "ollama": "llava",
        "capabilities": ["image-understanding", "visual-qa", "chat"],
        "safetyReview": "passed",
        "forkable": true
      },
      "bakllava": {
        "name": "BakLLaVA",
        "license": "Apache 2.0",
        "ollama": "bakllava",
        "capabilities": ["image-understanding", "visual-qa"],
        "safetyReview": "passed",
        "forkable": true
      }
    },

    "speech_models": {
      "whisper": {
        "name": "OpenAI Whisper",
        "sizes": ["tiny", "base", "small", "medium", "large-v3"],
        "license": "MIT",
        "huggingface": "openai/whisper-large-v3",
        "capabilities": ["speech-to-text", "transcription", "translation"],
        "safetyReview": "passed",
        "forkable": true
      }
    }
  },

  "securityChecks": {
    "requirements": [
      "Model weights must be publicly available",
      "Training methodology must be documented",
      "No known malicious training data",
      "Community-reviewed for safety issues",
      "License must allow inspection and modification"
    ],
    "automated": [
      "Toxicity detection on outputs",
      "Bias evaluation",
      "Prompt injection resistance",
      "Output validation"
    ]
  },

  "deployment": {
    "docker": {
      "ollama": "docker run -d -v ollama:/root/.ollama -p 11434:11434 ollama/ollama",
      "vllm": "docker run --gpus all -p 8000:8000 vllm/vllm-openai --model meta-llama/Llama-3.1-8B-Instruct",
      "tgi": "docker run --gpus all -p 8080:80 ghcr.io/huggingface/text-generation-inference --model-id meta-llama/Llama-3.1-8B-Instruct"
    },
    "kubernetes": {
      "docs": "https://ollama.ai/blog/run-llama2-on-kubernetes"
    }
  }
}
